{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "SA_Ex3.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSeXzYiT8Q2y",
    "colab_type": "text"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HibgsBc0tVH8",
    "colab_type": "code",
    "outputId": "93d21fb9-5ff1-434e-c546-aef7b0d2e291",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.compat.v2 as tf \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "tf.version.VERSION"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8IrENo7qBw8R",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "## matplotlib configuration\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 14\n",
    "BIG_SIZE = 16\n",
    "LARGE_SIZE = 20\n",
    "\n",
    "params = {\n",
    "    'figure.figsize': (14, 6),\n",
    "    'font.size': SMALL_SIZE,\n",
    "    'xtick.labelsize': MEDIUM_SIZE,\n",
    "    'ytick.labelsize': MEDIUM_SIZE,\n",
    "    'legend.fontsize': BIG_SIZE,\n",
    "    'figure.titlesize': LARGE_SIZE,\n",
    "    'axes.titlesize': MEDIUM_SIZE,\n",
    "    'axes.labelsize': BIG_SIZE\n",
    "}\n",
    "plt.rcParams.update(params)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Srq5R1RyGy1K",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def show_history(history):\n",
    "    plt.figure()\n",
    "    for key in history.history.keys():\n",
    "        plt.plot(history.epoch, history.history[key], label=key)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmBejzIk8YVk",
    "colab_type": "text"
   },
   "source": [
    "# YELP"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J2b9cEav8aKL",
    "colab_type": "code",
    "outputId": "1d3b3bcf-e74c-4d29-e64b-a0fb5786d875",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    }
   },
   "source": [
    "path = \"../data/YelpLemmatized.txt\"\n",
    "yelpData = pd.read_csv(path, sep='\\t', header=0, encoding=\"utf-8\")\n",
    "row_sizes = yelpData['SentimentText'].str.split().str.len()\n",
    "yelpData['SentimentText'] = yelpData['SentimentText'].str.lower()\n",
    "print(f\"Words count: {pd.Series.sum(row_sizes)}\")\n",
    "yelpData"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPPK7iKT9naI",
    "colab_type": "text"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NC0JCT1dAVfV",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "df = yelpData\n",
    "df['review_lenght'] = np.array(list(map(lambda x: len(x.split()), df['SentimentText'])))\n",
    "median = df['review_lenght'].median()\n",
    "mean = df['review_lenght'].mean()\n",
    "_max_length = df['review_lenght'].max()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zqyj8uNo_dnm",
    "colab_type": "code",
    "outputId": "e50642a3-0fa1-4255-8afa-16e4f465f878",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    }
   },
   "source": [
    "fig, ax = plt.subplots()\n",
    "sb.distplot( df['review_lenght'],  bins=int(_max_length),\n",
    "            hist_kws={\"alpha\": 0.9, \"color\": \"blue\"}, ax=ax,\n",
    "            kde_kws={\"color\": \"black\", 'linewidth': 3})\n",
    "ax.set_xlim(left=0, right=_max_length)\n",
    "ax.set_xlabel('Počet slov v recenzi')\n",
    "ymax = 0.1\n",
    "plt.ylim(0, ymax)\n",
    "ax.plot([mean, mean], [0, ymax], '--', label=f'průměr = {mean:.2f}', linewidth=3)\n",
    "ax.plot([median, median], [0, ymax], '--',\n",
    "        label=f'median = {median:.2f}', linewidth=3)\n",
    "ax.plot([_max_length, _max_length], [0, ymax], '--', label=f'max = {_max_length}', linewidth=0)\n",
    "# ax.set_title('Distribuce slov v recenzích', fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C67w3wgl9pD-",
    "colab_type": "code",
    "outputId": "627fee22-8fdd-440b-b87a-529bdda9aba7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    }
   },
   "source": [
    "df = yelpData\n",
    "max_dictionary_size = 2071\n",
    "tokenizer = Tokenizer(num_words=max_dictionary_size)\n",
    "tokenizer.fit_on_texts(df['SentimentText'])\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(df['SentimentText'])\n",
    "max_length = _max_length\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=max_length, padding='post')\n",
    "y = yelpData['Sentiment']\n",
    "len(tokenizer.index_word)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "co1jB1bMFcG4",
    "colab_type": "text"
   },
   "source": [
    "## LSTM 1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "67gLJwPaFWR8",
    "colab_type": "code",
    "outputId": "ed6c7bd1-0d35-4a6b-aa59-c0a51642f730",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "fold = 0\n",
    "results = list()\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                        min_delta=0,\n",
    "                                        patience=4,\n",
    "                                        verbose=1,\n",
    "                                        mode='auto',\n",
    "                                        restore_best_weights=True)\n",
    "\n",
    "for train, test in kfold.split(df['SentimentText'], y):\n",
    "    model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(max_dictionary_size, 64, input_length=max_length),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Bidirectional(keras.layers.LSTM(100, return_sequences=True)),\n",
    "    keras.layers.GlobalMaxPooling1D(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")                                \n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    model.fit(X_t[train],y[train], batch_size=8, epochs=12,  validation_data=(X_t[test], y[test]), callbacks=[early_stopping])\n",
    "    scores = model.evaluate(X_t[test], y[test])\n",
    "    results.append(scores[1])\n",
    "    fold += 1\n",
    "\n",
    "print(f\"Average accuracy = {sum(results)/fold * 100:0.2f} %\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6aNAwC2o-r7r"
   },
   "source": [
    "## LSTM 2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "outputId": "d4a450ed-f904-4640-9691-54b1881c5d41",
    "id": "bJFzS-2B-r77",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "fold = 0\n",
    "results = list()\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                        min_delta=0,\n",
    "                                        patience=4,\n",
    "                                        verbose=1,\n",
    "                                        mode='auto',\n",
    "                                        restore_best_weights=True)\n",
    "\n",
    "for train, test in kfold.split(df['SentimentText'], y):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Embedding(max_dictionary_size, 64, input_length=max_length, mask_zero=True),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.4),\n",
    "        keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPooling1D(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True)),\n",
    "        keras.layers.GlobalMaxPooling1D(),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(100),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")                             \n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    model.fit(X_t[train],y[train], batch_size=8, epochs=12,  validation_data=(X_t[test], y[test]), callbacks=[early_stopping])\n",
    "    scores = model.evaluate(X_t[test], y[test])\n",
    "    results.append(scores[1])\n",
    "    fold += 1\n",
    "\n",
    "print(f\"Average accuracy = {sum(results)/fold * 100:0.2f} %\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1uex1EAyfYDi",
    "colab_type": "text"
   },
   "source": [
    "## CNN 1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GFk9ObZmfa7A",
    "colab_type": "code",
    "outputId": "86a88eaf-42f2-483e-eba6-1427d967715c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "fold = 0\n",
    "results = list()\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                        min_delta=0,\n",
    "                                        patience=4,\n",
    "                                        verbose=1,\n",
    "                                        mode='auto',\n",
    "                                        restore_best_weights=True)\n",
    "for train, test in kfold.split(df['SentimentText'], y):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Embedding(max_dictionary_size, 50, input_length=max_length),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Conv1D(filters, kernel_size, activation=\"relu\"),\n",
    "        keras.layers.GlobalMaxPooling1D(),\n",
    "        keras.layers.Dense(250),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Activation(\"relu\"),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")                                \n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    model.fit(X_t[train],y[train], batch_size=8, epochs=10,  validation_data=(X_t[test], y[test]), callbacks=[early_stopping])\n",
    "    scores = model.evaluate(X_t[test], y[test])\n",
    "    results.append(scores[1])\n",
    "    fold += 1\n",
    "print(f\"Average accuracy = {sum(results)/fold * 100:0.2f} %\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c3BuIgbIVEHT"
   },
   "source": [
    "## CNN 2\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "outputId": "7473f15e-dd77-44be-c48b-c665b6b3bdd6",
    "id": "WQAHvicoVEHr",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "fold = 0\n",
    "results = list()\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                        min_delta=0,\n",
    "                                        patience=4,\n",
    "                                        verbose=1,\n",
    "                                        mode='auto',\n",
    "                                        restore_best_weights=True)\n",
    "\n",
    "for train, test in kfold.split(df['SentimentText'], y):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Embedding(max_dictionary_size, 64, input_length=max_length),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Conv1D(32, 7, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Conv1D(32, 3, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Conv1D(32, 3, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Conv1D(32, 3, padding='same', activation='relu'),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Conv1D(2, 2),\n",
    "        keras.layers.GlobalAveragePooling1D(),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")                                \n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    model.fit(X_t[train],y[train], batch_size=8, epochs=10,  validation_data=(X_t[test], y[test]), callbacks=[early_stopping])\n",
    "    scores = model.evaluate(X_t[test], y[test])\n",
    "    results.append(scores[1])\n",
    "    fold += 1\n",
    "print(f\"Average accuracy = {sum(results)/fold * 100:0.2f} %\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eg8L177zgN2f",
    "colab_type": "text"
   },
   "source": [
    "# IMDB"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xyAHbiZwgRHB",
    "colab_type": "code",
    "outputId": "5e28656f-c333-4d3f-acab-94a24a28277e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    }
   },
   "source": [
    "path = \"../data/Imdb50KLemmatized.tsv\"\n",
    "imdbData = pd.read_csv(path, sep='\\t', header=0, encoding=\"utf-8\", doublequote=False, escapechar=\"\\\\\")\n",
    "imdbData = imdbData.drop(['id'], axis=1)\n",
    "row_sizes = imdbData['SentimentText'].str.split().str.len()\n",
    "imdbData['SentimentText'] = imdbData['SentimentText'].str.lower()\n",
    "print(f\"Words count: {pd.Series.sum(row_sizes)}\")\n",
    "imdbData"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mthjIcvVgX0l",
    "colab_type": "text"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GPJYTQYFgn57",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "df = imdbData\n",
    "df['review_lenght'] = np.array(list(map(lambda x: len(x.split()), df['SentimentText'])))\n",
    "median = df['review_lenght'].median()\n",
    "mean = df['review_lenght'].mean()\n",
    "_max_length = df['review_lenght'].max()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3Pff_EyGgwEz",
    "colab_type": "code",
    "outputId": "b404e879-f488-4012-f958-36df464f7e02",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    }
   },
   "source": [
    "fig, ax = plt.subplots()\n",
    "sb.distplot( df['review_lenght'],  bins=int(_max_length/4),\n",
    "            hist_kws={\"alpha\": 0.9, \"color\": \"blue\"}, ax=ax,\n",
    "            kde_kws={\"color\": \"black\", 'linewidth': 3})\n",
    "ax.set_xlim(left=0, right=_max_length/4)\n",
    "ax.set_xlabel('Počet slov v recenzi')\n",
    "ymax = 0.008\n",
    "plt.ylim(0, ymax)\n",
    "ax.plot([mean, mean], [0, ymax], '--', label=f'průměr = {mean:.2f}', linewidth=3)\n",
    "ax.plot([median, median], [0, ymax], '--',\n",
    "        label=f'median = {median:.2f}', linewidth=3)\n",
    "ax.plot([_max_length, _max_length], [0, ymax], '--', label=f'max = {_max_length}', linewidth=0)\n",
    "# ax.set_title('Distribuce slov v recenzích', fontsize=20)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IpLm0t-Th1sw",
    "colab_type": "code",
    "outputId": "9c8e2366-bb37-4e1a-99af-a9629c06959b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    }
   },
   "source": [
    "# tokenization and padding\n",
    "max_dictionary_size = 10000\n",
    "tokenizer = Tokenizer(num_words=max_dictionary_size)\n",
    "tokenizer.fit_on_texts(df['SentimentText'])\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(df['SentimentText'])\n",
    "max_length = 400\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=max_length, padding='post')\n",
    "y = imdbData['Sentiment']\n",
    "len(tokenizer.index_word)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rpzx3Cjrgc9l",
    "colab_type": "text"
   },
   "source": [
    "## LSTM 1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4eYazwhbh42j",
    "colab_type": "code",
    "outputId": "17aba032-37a2-4431-e983-089008cd2b30",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "fold = 0\n",
    "results = list()\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                        min_delta=0,\n",
    "                                        patience=3,\n",
    "                                        verbose=1,\n",
    "                                        mode='auto',\n",
    "                                        restore_best_weights=True)\n",
    "\n",
    "for train, test in kfold.split(df['SentimentText'], y):\n",
    "    print(f\"******* Fold {fold + 1} ***********\")\n",
    "    model = keras.models.Sequential([\n",
    "            keras.layers.Embedding(max_dictionary_size, 64, input_length=max_length),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dropout(0.4),\n",
    "            keras.layers.Bidirectional(keras.layers.LSTM(100, return_sequences=True)),\n",
    "            keras.layers.GlobalMaxPooling1D(),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dense(100),\n",
    "            keras.layers.Dropout(0.3),\n",
    "            keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    model.fit(X_t[train],y[train], batch_size=64, epochs=10, validation_data=(X_t[test], y[test]), callbacks=[early_stopping])\n",
    "    scores = model.evaluate(X_t[test], y[test])\n",
    "    results.append(scores[1])\n",
    "    fold += 1\n",
    "print(f\"Average accuracy = {sum(results)/fold * 100:0.2f} %\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LSTM 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "fold = 0\n",
    "results = list()\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                        min_delta=0,\n",
    "                                        patience=3,\n",
    "                                        verbose=1,\n",
    "                                        mode='auto',\n",
    "                                        restore_best_weights=True)\n",
    "\n",
    "for train, test in kfold.split(df['SentimentText'], y):\n",
    "    print(f\"******* Fold {fold + 1} ***********\")\n",
    "    model = keras.models.Sequential([\n",
    "            keras.layers.Embedding(max_dictionary_size, 64, input_length=max_length, mask_zero=True),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dropout(0.4),\n",
    "            keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True)),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.MaxPooling1D(),\n",
    "            keras.layers.Dropout(0.3),\n",
    "            keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True)),\n",
    "            keras.layers.GlobalMaxPooling1D(),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dense(100),\n",
    "            keras.layers.Dropout(0.3),\n",
    "            keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    model.fit(X_t[train],y[train], batch_size=64, epochs=10, validation_data=(X_t[test], y[test]), callbacks=[early_stopping])\n",
    "    scores = model.evaluate(X_t[test], y[test])\n",
    "    results.append(scores[1])\n",
    "    fold += 1\n",
    "print(f\"Average accuracy = {sum(results)/fold * 100:0.2f} %\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoOI0hJSgeJu",
    "colab_type": "text"
   },
   "source": [
    "## CNN 1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yWXdFuzTgfLs",
    "colab_type": "code",
    "outputId": "1231a08d-bdbf-46e8-e7e2-385f1aa45406",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "fold = 0\n",
    "results = list()\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                        min_delta=0,\n",
    "                                        patience=3,\n",
    "                                        verbose=1,\n",
    "                                        mode='auto',\n",
    "                                        restore_best_weights=True)\n",
    "\n",
    "for train, test in kfold.split(df['SentimentText'], y):\n",
    "    print(f\"******* Fold {fold + 1} ***********\")\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Embedding(max_dictionary_size, 50, input_length=max_length),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Conv1D(filters, kernel_size, activation=\"relu\"),\n",
    "        keras.layers.GlobalMaxPooling1D(),\n",
    "        keras.layers.Dense(250),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Activation(\"relu\"),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")                                \n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    model.fit(X_t[train],y[train], batch_size=32, epochs=10, validation_data=(X_t[test], y[test]), callbacks=[early_stopping])\n",
    "    scores = model.evaluate(X_t[test], y[test])\n",
    "    results.append(scores[1])\n",
    "    fold += 1\n",
    "print(f\"Average accuracy = {sum(results)/fold * 100:0.2f} %\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CNN 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "fold = 0\n",
    "results = list()\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_accuracy',\n",
    "                                        min_delta=0,\n",
    "                                        patience=3,\n",
    "                                        verbose=1,\n",
    "                                        mode='auto',\n",
    "                                        restore_best_weights=True)\n",
    "\n",
    "for train, test in kfold.split(df['SentimentText'], y):\n",
    "    print(f\"******* Fold {fold + 1} ***********\")\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Embedding(max_dictionary_size, 64, input_length=max_length),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Conv1D(32, 7, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Conv1D(32, 3, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Conv1D(32, 3, padding='same', activation='relu'),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Conv1D(32, 3, padding='same', activation='relu'),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Conv1D(2, 2),\n",
    "        keras.layers.GlobalAveragePooling1D(),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "    model.fit(X_t[train],y[train], batch_size=32, epochs=10, validation_data=(X_t[test], y[test]), callbacks=[early_stopping])\n",
    "    scores = model.evaluate(X_t[test], y[test])\n",
    "    results.append(scores[1])\n",
    "    fold += 1\n",
    "print(f\"Average accuracy = {sum(results)/fold * 100:0.2f} %\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}